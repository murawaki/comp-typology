*About

  Yugo Murawaki. 2015. Continuous Space Representations of Linguistic
  Typology and their Application to Phylogenetic Inference.  In
  Proceedings of the 2015 Conference of the North American Chapter of
  the Association for Computational Linguistics: Human Language
  Technologies (NAACL-HLT 2015), pp. 324-334.


*Requirements

- Python2
  - numpy
<DEL>
- Perl (for preprocessing)
</DEL>
- R (for missing data imputation)
  - missMDA package


*Data setup
  The main outputs are (in data/ dir):
<DEL>
  - tree.json: Ethnologue tree
  - walstree.json: two-level WALS tree
  - features.json: WALS features (after thresholding)
</DEL>
  - langs.json: set of languages for the PARTIAL data with missing data imputed
  - langs_all.json: set of languages for the FULL data with missing data imputed


- Download language.csv from WALS http://wals.info/

- Manually modify language.csv to obtain language.modified.csv
  (added some glottocodes available online)

- Convert language.modified.csv to 2 json files (and remove "Sign Languages" and "Creoles and Pidgins")
  % python format_wals/csv2json.py ../data/wals/language.modified.csv ../data/wals/langs_all.json ../data/wals/flist_all.json

- Fill logically determined items
  % python format_wals/logical.py ../data/wals/langs_all.json ../data/wals/flist_all.json ../data/wals/langs_aug.json ../data/wals/flist_aug.json

- Remove low-coverage features (in terms of the number of languages)
  % python format_wals/fthres.py --fthres=0.1 ../data/wals/langs_aug.json ../data/wals/flist_aug.json ../data/wals/langs_full.json ../data/wals/flist.json

- Remove low-coverage languages (in terms of the number of features)
  % python format_wals/lthres.py --lthres=0.3 --removed ../data/wals/langs_removed.json ../data/wals/langs_full.json ../data/wals/flist.json ../data/wals/langs.json





<DEL>
  % cd scripts
  % perl format_wals/langlist.pl < ../data/wals/language.modified.csv > ../data/wals/langlist.out 2> ../data/wals/langlist.err


- Download Ethnologue pages using WALS's ISO codes

  % cd data/ethnologue
  % perl -anle '{if (! -f $F[0]){ printf "http://www.ethnologue.com/language/%s\n", $F[0]; }}' < ../wals/langlist.out | wget -i - -w 60

- Extract classifications from Ethnologue pages

  % for f in ???; do echo -e "$f\t"`cat $f | perl -nle'if(/<div class=\"field-label\">Classification<\/div>/){$flag=1;}if($flag and /\">([^<]+)<\/a>/) { print $1; exit }'`; done > ../wals/ethnologue_classifications


- Create JSON files
  - Notes:
    - Language isolates are put directly under ROOT
    - Intermediate nodes that have only one child are removed
    - If multiple languages share the same ISO code, they are put under an intermediate node
    - Languages labeled as "Deaf sign language", "Mixed language" or others are removed

  % cd scripts
  % perl format_wals/format.pl ../data/wals/langlist.out ../data/wals/language.modified.csv ../data/wals/ethnologue_classifications ../data/tree.json ../data/features_all.json ../data/walstree.json
</DEL>




*Missing data imputation

- For the PARTIAL dataset:

  % python mv/json2tsv.py ../data/wals/langs.json ../data/wals/flist.json ../data/wals/langs.tsv
  % R --vanilla -f mv/impute_mca.r --args ../data/wals/langs.tsv ../data/wals/langs.filled.tsv
  % python mv/tsv2json.py ../data/wals/langs.json ../data/wals/langs.filled.tsv ../data/wals/flist.json ../data/wals/langs.filled.json

- For the FULL dataset:

  % python mv/json2tsv.py ../data/wals/langs_full.json ../data/wals/flist.json ../data/wals/langs_full.tsv
  % R --vanilla -f mv/impute_mca.r --args ../data/wals/langs_full.tsv ../data/wals/langs_full.filled.tsv
  % python mv/tsv2json.py ../data/wals/langs_full.json ../data/wals/langs_full.filled.tsv ../data/wals/flist.json ../data/wals/langs_full.filled.json


**Evaluating missing data imputation by cross-validation

  % make -j 8 -f mv/cv/autoeval.make all CV=10



* Attach categorical vectors

  % python format_wals/catvect.py ../data/wals/langs.filled.json ../data/wals/flist.json ../data/langs.json
  % python format_wals/catvect.py ../data/wals/langs_full.filled.json ../data/wals/flist.json ../data/langs_full.json


* Train the evaluator

  % python train.py --seed=20 --minibatch=10 --eta=0.1 --Cscore=0.1 --iter=1000 --nested --dims=100 --dims2=10 ../data/langs.json ../data/wals/flist.json ../data/model_nested_100_010.json 2>&1 | tee ../data/model_nested_100_010.log




* Mix two languages

  Source and destination languages are specified by WALS code

  - German (ger) and English (eng)

  % python mix_langs.py --src=ger --dst=eng --hid ../data/model_nested_100_010.json ../data/langs.json | tee ../data/mix/ger_eng_nested_hid
  % python mix_langs.py --src=ger --dst=eng --hid --auto  ../data/model_nested_100_010.json ../data/langs.json | tee ../data/mix/ger_eng_nested_hid2
  % python mix_langs.py --src=ger --dst=eng --cat ../data/model_nested_100_010.json ../data/langs.json | tee ../data/mix/ger_eng_nested_cat

  # gnuplot
  plot "ger_eng_nested_cat" using 1:2 with lines title "cat", "ger_eng_nested_cat" using 1:2:3 with yerr notitle, "ger_eng_nested_hid" using 1:2 with lines title "hid (orig)", "ger_eng_nested_hid2" using 1:2 with lines title "hid (binarized)"


  - Khmer (khm) and Kharia (khr)

  % python mix_langs.py --src=khm --dst=khr --hid ../data/model_nested_100_010.json ../data/langs.json | tee ../data/mix/khm_khr_nested_hid
  % python mix_langs.py --src=khm --dst=khr --hid --auto  ../data/model_nested_100_010.json ../data/langs.json | tee ../data/mix/khm_khr_nested_hid2
  % python mix_langs.py --src=khm --dst=khr --cat ../data/model_nested_100_010.json ../data/langs.json | tee ../data/mix/khm_khr_nested_cat

  plot "khm_khr_nested_cat" using 1:2 with lines title "cat", "khm_khr_nested_cat" using 1:2:3 with yerr notitle, "khm_khr_nested_hid" using 1:2 with lines title "hid (orig)", "khm_khr_nested_hid2" using 1:2 with lines title "hid (binarized)"




* Tree

  In NAACL 2015, we used the Ethnologue classification, but we now use Glottolog.

  - Download Glottolog classification

  % cd data/glottolog
  % wget http://glottolog.org/static/trees/tree-glottolog-newick.txt

<DEL>
  - Download Glottocodes

  % wget http://glottolog.org/resourcemap.json?rsc=language
</DEL>

  - Convert Newick format into Python pickle (JSON is not used due to cyclic links)

  % python glottolog/newick_tree.py ../data/glottolog/tree-glottolog-newick.txt ../data/glottolog/trees.pkl

  - Merge Glottolog trees with WALS languages

  % python glottolog/merge.py ../data/langs.json ../data/glottolog/trees.pkl ../data/trees.json

  % python glottolog/merge.py --lthres=0.3 ../data/langs_full.json ../data/glottolog/trees.pkl ../data/trees_full.json



* JSAI 2016 small experiment

  % python format_wals/jsai2016.py ../data/wals/langs_all.json ../data/wals/flist_all.json
